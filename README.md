# Introduction and background #
Generative AI systems are known to perpetuate and exacerbate existing human biases and harms. Studies have confirmed the existence of a notable gender gap in the usage and exploration of Generative AI despite its significant advancements. Compared to women, men are more likely to experiment and adopt Generative AI tools; women remain underrepresented in this rapidly evolving field. This gender inequality has implications for both individual opportunities and societal progress.


# Research Questions #
1.	What factors contribute to the gender gap in generative AI usage? 
2. How do perceptions of generative AI differ between men and women? 
3. Does user trust in AI platforms impact their platform usage?


# Objective #
This project aims to determine the factors impacting gender disparity in generative AI usage. The study will empower more women to utilize generative AI, bridge the gender gap, and raise awareness about the potential biases and harms associated with these systems. Our participation in the Datathon will help ensure that generative AI is developed and used in an inclusive, equitable, and beneficial way.


# Problem-solving approach #
### Descriptive and inferential analysis ###

Conduct a thorough analysis of the survey data to identify key trends, patterns, and areas of concern.

### Qualitative analysis ###

Explore the open-ended responses to gain deeper insights into user experiences and perceptions.

### Comparative analysis ###

Compare the responses across different demographics, platforms, and usage frequencies.

### Identify themes ###

Extract common themes and patterns from the data to inform recommendations and actions.


# Stakeholders/Audience in the Study of Gender Gap in Generative AI #
### Researchers and Academics ###
   
The goal is to understand the factors contributing to the gender gap, develop strategies to address it, and advance knowledge in the field of AI.

### Technology Companies ###
   
The goal is to ensure that their AI products and services are inclusive and accessible to a diverse user base. This can improve product development, market reach, and public perception.

### Government Agencies ###
   
The goal is to promote gender equality in technology and ensure that AI is developed and used ethically. This can contribute to social and economic development.

### Educational Institutions ###
   
The goal is to provide equitable access to STEM education and training, particularly for women. This can help to increase the diversity of talent in the AI workforce.

### Non-Governmental Organizations (NGOs) ###
    
The goal is to advocate for gender equality and social justice in the context of AI. This can raise awareness of the issue and support initiatives to address it.

### Women in Technology Groups ###
    
The goal is to empower women in the tech industry and provide support and resources. This can help to close the gender gap and create a more inclusive environment.

### General Public ###
    
The goal is to benefit from the advancements of AI while ensuring that it is developed and used ethically. This can improve quality of life, access to information, and economic opportunities.


# Data #
Primary data was collected specifically for this research. The variables include: 
Age, Education, Platform, AI_usage, AI_usage_frequency ,Response_time,Accuracy,Quality ,Satisfaction,Bias ,Bias_category, Harmful_content ,Harmful_content_type ,Security,Overall_performance ,New_features, Improvement, and Ethical_considerations. 
The sample consists of 115 respondents (n = 115); 60 females and 55 males. The link to the data is https://docs.google.com/spreadsheets/d/1gcYrbeBhQJI_FC4tGKoPNa5-MWmhIhQaw1pW59YXOmM/edit?usp=sharing


# Data Cleaning #
Created a dataframe

Converted the data types

Handled the missing values

Checked for duplicates

Checked for outliers


# Inferential Statistics #
1.The chi-squared test identified if there are significant differences in platform usage between genders. 

2.Logistic Regression was used to predict generative AI usage based on a set of predictor variables (age, education, platform type, quality, and accuracy). 

3.The chi-squared test determined if there are significant differences in ethical concerns (bias, harmful content, and security) between genders. 

4.Textual analysis anayzed the open ended responses to identify recurring themes and keywords related to stereotypes and biases.


# Key Findings #
1.	Our data revealed a concerning gender gap in generative AI usage. We found that compared to men, women are not likely to experiment and adopt Generative AI tools.

2.	The key factors that contribute to the disparity in generative AI usage include platform preference, quality of responses, education, and age. Higher perceived quality of responses was associated with higher AI usage. The use of the Chat GPT platform was associated with a higher likelihood of using AI. Older age and higher education levels were associated with higher AI usage. Higher accuracy was linked to lower AI usage, but the effect was relatively small.

3.	Security was an evident gender-specific stereotype that influenced how men and women view generative AI systems.  Women were found to be more concerned about the safety of their personal information which might be a barrier leading to hesitancy in adopting the technology. Both male and female respondents had equal perceptions of the existence of harmful or misleading content generated by the platform and the biases of the platform's output.

4.	Misinformation was the most frequently mentioned harmful content type in the dataset, suggesting that misinformation is a significant concern. It may represent false information spread deliberately or unintentionally, impacting public perception. Deepfakes are less commonly mentioned compared to misinformation. However, their presence indicates a growing awareness of this technology, which can create realistic but fabricated content, potentially leading to misinformation or defamation.

5.	Location was found to be the most frequent bias category. 
Geographical factors can influence the training data and decision-making processes of AI systems. Bias may arise if AI models are trained predominantly on data from specific regions leading to underrepresentation of other locations. 


# Limitations #
###  Sample Size and Diversity ###

The sample size was not large enough and representative of the population to draw meaningful conclusions.


# Recommendations #
### Diversity and Inclusion ###

Ensure that AI platforms are trained on diverse datasets to reduce biases and improve accuracy for users from various backgrounds. Engage with users from different backgrounds during the development phase to understand their needs and potential biases in AI outputs.
   
### Fact-Checking and Verification ###

Implement robust mechanisms to detect and mitigate the spread of misinformation and deepfakes.
   
### Privacy and Security ###

Prioritize user privacy and data security to build trust and protect sensitive information.
   
### Personalization ###

Develop features that allow users to customize their AI experience based on their preferences and needs.
   
### Continuous Improvement ###

Engage in ongoing research and development to address emerging challenges and improve AI capabilities. Establish frameworks for continuous monitoring of AI systems to ensure they remain fair and unbiased over time, adapting to changes in societal norms and values.
    
### A user-friendly platform ### 

Platform that integrates well into existing workflows, combined with high-quality, and accurate responses, creates an attractive offering for users.
    
### Consider focusing efforts on combatting misinformation, given its high frequency ### 

Explore educational initiatives or policies aimed at addressing the implications of deepfakes. Investigate the context of hate speech occurrences to ensure comprehensive coverage of harmful content issues.
    
### Bias Audits ### 

Implement regular audits of AI systems to identify and mitigate biases related to these factors, using diverse teams for evaluation.


# Actionable next steps #
### Data Analysis ###

Conduct a more in-depth analysis of the survey data to identify specific areas where improvements are needed. We will consider exploring other factors that might contribute to the gender gap, such as cultural norms, stereotypes, and exposure to AI.

### Longitudinal Studies ###

We can conduct longitudinal studies to track changes in AI usage over time and identify how factors like age and education may evolve.

### Qualitative research ###

We can combine quantitative analysis with qualitative methods (interviews, focus groups) to gain deeper insights into the reasons behind gender differences in AI usage.

### User Feedback ### 

Establish channels for ongoing user feedback and engagement to gather insights and inform platform development.
Bias Mitigation: Develop and implement strategies to address biases and ensure fairness in AI outputs.

### Ethical Guidelines ###

Create ethical guidelines for AI development and deployment to ensure responsible and accountable use.
Collaboration: Foster collaboration among researchers, developers, and policymakers to address the challenges and opportunities presented by AI.


# Empowering Women to Use Generative AI #
To bridge the gender gap in generative AI usage, it is essential to address the barriers that prevent women from adopting and using these tools.

### Community-Building ###
Organize AI communities and meetups specifically for women to foster a sense of belonging and support.

### Role Models  ###
Highlight successful women in AI to inspire others and challenge stereotypes.

### Accessible Resources ###
Develop user-friendly AI tools and resources that are inclusive and easy to learn.









